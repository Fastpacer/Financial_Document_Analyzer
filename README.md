# ğŸ“Š Financial Document Analyzer
## ğŸš€ AI Internship Assignment Submission
### ğŸ¯ Objective
Debug and productionize an intentionally broken CrewAI-based financial document analysis system.


### â–¶ï¸ How to Run the Application (Step-by-Step)
ğŸ–¥ System Requirements

Python 3.10 or higher

pip

Groq API Key (Free Tier Supported)

1ï¸âƒ£ Clone the Repository
git clone <your_repository_url>
cd Financial_Document_Analyzer
2ï¸âƒ£ Create & Activate Virtual Environment
Windows
python -m venv venv
venv\Scripts\activate
macOS / Linux
python3 -m venv venv
source venv/bin/activate
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
pip install litellm
4ï¸âƒ£ Configure Environment Variables

Create a .env file in the root directory:

GROQ_API_KEY=your_groq_api_key_here

Or set temporarily in terminal:

Windows
set GROQ_API_KEY=your_groq_api_key_here
macOS / Linux
export GROQ_API_KEY=your_groq_api_key_here
5ï¸âƒ£ Run Backend (FastAPI)
uvicorn app.main:app --reload

Backend will start at:

http://127.0.0.1:8000

You can verify API docs at:

http://127.0.0.1:8000/docs
6ï¸âƒ£ Run Frontend (Streamlit)

Open a new terminal (keep backend running):

streamlit run frontend/streamlit_app.py

Frontend will open in browser automatically.

### ğŸ§ª How to Test the Application

Upload any financial PDF document

Provide an optional analysis query

Click Analyze Document

View structured

## ğŸ“Œ Project Overview
This project is a production-ready financial document analysis system built using:

FastAPI (Backend API)

CrewAI (Agent orchestration)

Groq LLM via LiteLLM

SQLite (SQLAlchemy ORM)

Streamlit (Frontend Demo UI)

The original repository contained:

Deterministic runtime bugs

Incorrect tool definitions

Invalid LLM configuration

Inefficient prompt design

Token overflow issues

Broken database integration

âœ… All identified issues have been resolved and the system has been refactored into a stable, production-grade architecture.

## ğŸ§  System Architecture
Code
Streamlit Frontend
        â†“
FastAPI Backend
        â†“
CrewAI Agent
        â†“
Groq LLM (LiteLLM Router)
        â†“
SQLite Database
ğŸ›  Bugs Identified & Fixes Implemented
1ï¸âƒ£ Tool Validation Error (CrewAI + Pydantic)
âŒ Problem: Raw function was passed as a tool.

python
tools=[FinancialDocumentTool.read_data_tool]
âœ… Fix: Refactored tool to inherit from BaseTool.

python
class FinancialDocumentTool(BaseTool):
    ...
tools=[FinancialDocumentTool()]
2ï¸âƒ£ OpenAI API Key Error
âŒ Problem: CrewAI defaulted to OpenAI provider internally.
Error: OPENAI_API_KEY is required

âœ… Fix: Switched to official CrewAI LLM wrapper.

python
llm = LLM(model="groq/llama3-8b-8192")
Environment variable: GROQ_API_KEY

3ï¸âƒ£ LiteLLM Fallback Error
âŒ Problem: Fallback to LiteLLM not available.
âœ… Fix: Installed dependency:

bash
pip install litellm
4ï¸âƒ£ Incorrect Model (Whisper Used for Chat)
âŒ Problem: whisper-large-v3-turbo does not support chat completions.
âœ… Fix: Replaced with valid Groq chat model:
groq/llama3-8b-8192

5ï¸âƒ£ Groq Token Rate Limit (TPM Overflow)
âŒ Problem: Full PDF passed to LLM â†’ exceeded 10k tokens/min.
Error: RateLimitError: Requested 12588 tokens

âœ… Fix (Production Decision):

python
MAX_CHARS = 8000
full_text = full_text[:MAX_CHARS]
ğŸ¯ Tradeoff:

Prevents token overflow

Free-tier compatible

Avoids complex chunking/RAG

6ï¸âƒ£ SQLAlchemy Import Error
âŒ Problem: AnalysisResult model missing.
âœ… Fix: Proper ORM model created.

python
class AnalysisResult(Base):
    ...
7ï¸âƒ£ Celery + Redis Instability (Windows)
âŒ Problem: Celery worker failed repeatedly, Redis setup complex.
ğŸ¯ Decision: Removed Celery â†’ synchronous processing.

## Tradeoff:

Stability > unnecessary concurrency

Focused on core assignment objectives

Reduced operational complexity

âœ¨ Prompt Engineering Improvements
Original prompts encouraged:

Hallucinations

Fake URLs

Contradictions

Non-compliant financial advice

âœ… Refactored Agent Prompt:

Evidence-based analysis only

Structured output

No speculative investment claims

Professional tone

## ğŸ“‚ Final Repository Structure
Code
Financial_Document_Analyzer/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ agents.py
â”‚   â”œâ”€â”€ task.py
â”‚   â”œâ”€â”€ tools.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ crud.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ analysis.db
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone Repository

bash
git clone <your_repo_url>
cd Financial_Document_Analyzer
2ï¸âƒ£ Create Virtual Environment

bash
python -m venv venv
venv\Scripts\activate
3ï¸âƒ£ Install Dependencies

bash
pip install -r requirements.txt
pip install litellm
4ï¸âƒ£ Set Groq API Key  
Create .env file:

Code
GROQ_API_KEY=your_groq_key_here
5ï¸âƒ£ Run Backend

bash
uvicorn app.main:app --reload
6ï¸âƒ£ Run Frontend

bash
streamlit run frontend/streamlit_app.py
ğŸ”Œ API Documentation
POST /analyze
Uploads PDF and returns analysis.

Request:

file: PDF file

query: Optional analysis prompt

Response:

json
{
  "record_id": 1,
  "analysis": "Structured financial analysis..."
}
GET /result/{record_id}
Fetch stored analysis result.

## ğŸ¯ Key Design Choices
Challenge	Decision	Reason
LLM Provider	Groq	Free-tier compatible
Token Overflow	Truncation	Simplicity & reliability
Background Jobs	Removed	Stability under time constraint
Database	SQLite	Lightweight + sufficient
Frontend	Streamlit	Fast demo-ready UI
ğŸ§© Constraints Encountered
Groq free-tier TPM limits

CrewAI strict tool validation

LiteLLM dependency requirement

Windows Redis incompatibility

Model compatibility issues

âœ… All were resolved systematically.
